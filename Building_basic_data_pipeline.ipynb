{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO81gZsJwBo+6xLZIDk8TgX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Francisss3/Data-Engineering/blob/main/Building_basic_data_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQvy6qv1tQTH",
        "outputId": "4ac0140b-95e0-4297-ba4b-aa11a1f07b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.13.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas pymongo dnspython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [code]\n",
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "import logging\n",
        "import sys"
      ],
      "metadata": {
        "id": "vqTA2j1DtsL3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Setup logging\n",
        "logger = logging.getLogger('etl_pipeline')\n",
        "logger.setLevel(logging.INFO)\n",
        "fh = logging.FileHandler('pipeline.log')\n",
        "fh.setLevel(logging.INFO)\n",
        "fmt = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
        "fh.setFormatter(fmt)\n",
        "logger.addHandler(fh)"
      ],
      "metadata": {
        "id": "F-JYlRMotv5Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(path: str) -> pd.DataFrame:\n",
        "    \"\"\"Read CSV into DataFrame, log any errors.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(path, encoding='latin1')\n",
        "        logger.info(f\"Extracted {len(df)} rows from {path}\")\n",
        "        return df\n",
        "    except FileNotFoundError as e:\n",
        "        logger.error(f\"File not found: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to read CSV: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "X6nAV61EtyqA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Compute revenue per line then aggregate to total revenue per order.\"\"\"\n",
        "    try:\n",
        "        # calculate line-level revenue\n",
        "        df['line_revenue'] = df['QUANTITYORDERED'] * df['PRICEEACH']\n",
        "        logger.info(\"Added column 'line_revenue' = QUANTITYORDERED * PRICEEACH\")\n",
        "\n",
        "        # aggregate per transaction (ORDERNUMBER)\n",
        "        agg = (\n",
        "            df\n",
        "            .groupby('ORDERNUMBER', as_index=False)['line_revenue']\n",
        "            .sum()\n",
        "            .rename(columns={'ORDERNUMBER': 'transaction_id',\n",
        "                             'line_revenue': 'total_revenue'})\n",
        "        )\n",
        "        logger.info(f\"Aggregated to {len(agg)} unique transactions\")\n",
        "        return agg\n",
        "\n",
        "    except KeyError as e:\n",
        "        logger.error(f\"Missing expected column: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Transformation error: {e}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "q6Jfxy_ht4Aj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load(df: pd.DataFrame, uri: str):\n",
        "    \"\"\"Insert the transformed DataFrame into MongoDB.\"\"\"\n",
        "    try:\n",
        "        client = MongoClient(uri)\n",
        "        db = client.ecommerce\n",
        "        col = db.transactions\n",
        "        records = df.to_dict(orient='records')\n",
        "        res = col.insert_many(records)\n",
        "        logger.info(f\"Loaded {len(res.inserted_ids)} records into MongoDB\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Loading error: {e}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "o6h5NnSWt7Fq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    CSV_PATH = '/content/sales_data_sample.csv'\n",
        "    MONGO_URI = (\n",
        "        \"mongodb+srv://charbelfrancis03:\"\n",
        "        \"hUmsVOJeW3LRlLZ6\"\n",
        "        \"@cluster0.8otd0br.mongodb.net/\"\n",
        "        \"?retryWrites=true&w=majority\"\n",
        "    )\n",
        "\n",
        "    # Run ETL\n",
        "    df_raw = extract(CSV_PATH)\n",
        "    df_trans = transform(df_raw)\n",
        "    load(df_trans, MONGO_URI)\n",
        "    logger.info(\"ETL pipeline completed successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        logger.critical(f\"ETL pipeline failed: {e}\")\n",
        "        sys.exit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRhWjzmuuA3p",
        "outputId": "0a82cd8a-c35b-40e0-a46d-582881577d67"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:etl_pipeline:Extracted 2823 rows from /content/sales_data_sample.csv\n",
            "INFO:etl_pipeline:Added column 'line_revenue' = QUANTITYORDERED * PRICEEACH\n",
            "INFO:etl_pipeline:Aggregated to 307 unique transactions\n",
            "INFO:etl_pipeline:Loaded 307 records into MongoDB\n",
            "INFO:etl_pipeline:ETL pipeline completed successfully.\n"
          ]
        }
      ]
    }
  ]
}